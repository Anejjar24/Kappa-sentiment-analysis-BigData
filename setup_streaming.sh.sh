#!/bin/bash

echo "========================================"
echo "CONFIGURATION STREAMING YOUTUBE COMMENTS"
echo "API YouTube â†’ NiFi â†’ Kafka â†’ Spark â†’ ES"
echo "========================================"

# Couleurs
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

export MSYS_NO_PATHCONV=1

# Fonction pour vÃ©rifier si un service est prÃªt
check_service() {
    local service=$1
    local url=$2
    local max_attempts=20
    local attempt=0
    
    echo -e "${YELLOW}VÃ©rification de $service...${NC}"
    while [ $attempt -lt $max_attempts ]; do
        if curl -sf "$url" > /dev/null 2>&1; then
            echo -e "${GREEN}âœ“ $service est prÃªt!${NC}"
            return 0
        fi
        attempt=$((attempt + 1))
        sleep 2
    done
    
    echo -e "${RED}âŒ $service non accessible${NC}"
    return 1
}

# 1. VÃ©rifier que les modÃ¨les sont entraÃ®nÃ©s
echo -e "\n${BLUE}[1/6] VÃ©rification des modÃ¨les ML...${NC}"
if [ ! -d "models/Logistic_Regression_model" ] && \
   [ ! -d "models/Random_Forest_model" ] && \
   [ ! -d "models/Naive_Bayes_model" ] && \
   [ ! -d "models/Decision_Tree_model" ]; then
    echo -e "${RED}âŒ Aucun modÃ¨le trouvÃ©!${NC}"
    echo "Veuillez d'abord entraÃ®ner les modÃ¨les avec: ./setup_comparison.sh"
    exit 1
fi
echo -e "${GREEN}âœ“ ModÃ¨les ML trouvÃ©s${NC}"

# 2. VÃ©rifier les conteneurs Docker
echo -e "\n${BLUE}[2/6] VÃ©rification des conteneurs...${NC}"

# VÃ©rifier les conteneurs essentiels
REQUIRED_CONTAINERS=("kafka" "spark-master" "elasticsearch")
MISSING_CONTAINERS=()

for container in "${REQUIRED_CONTAINERS[@]}"; do
    if ! docker ps | grep -q "$container"; then
        MISSING_CONTAINERS+=("$container")
    fi
done

if [ ${#MISSING_CONTAINERS[@]} -gt 0 ]; then
    echo -e "${YELLOW}âš  Conteneurs manquants: ${MISSING_CONTAINERS[*]}${NC}"
    echo -e "${BLUE}DÃ©marrage des conteneurs...${NC}"
    docker-compose up -d
    sleep 15
else
    echo -e "${GREEN}âœ“ Tous les conteneurs sont actifs${NC}"
fi

# 3. Attendre que les services soient prÃªts
echo -e "\n${BLUE}[3/6] Attente des services...${NC}"
check_service "Elasticsearch" "http://localhost:9200"
sleep 5

# 4. VÃ©rifier les topics Kafka
echo -e "\n${BLUE}[4/6] VÃ©rification des topics Kafka...${NC}"

# Lister les topics existants
echo -e "${GREEN}Topics Kafka disponibles:${NC}"
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# CrÃ©er le topic sentiment-results s'il n'existe pas
docker exec kafka kafka-topics --create \
  --topic sentiment-results \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1 2>/dev/null && \
  echo -e "${GREEN}âœ“ Topic 'sentiment-results' crÃ©Ã©${NC}" || \
  echo -e "${YELLOW}Topic 'sentiment-results' existe dÃ©jÃ ${NC}"

# VÃ©rifier que le topic d'entrÃ©e existe
if docker exec kafka kafka-topics --list --bootstrap-server localhost:9092 | grep -q "tweets-validated"; then
    echo -e "${GREEN}âœ“ Topic 'tweets-validated' trouvÃ©${NC}"
else
    echo -e "${YELLOW}âš  Topic 'tweets-validated' non trouvÃ©${NC}"
    echo "Assurez-vous que NiFi envoie des donnÃ©es vers ce topic"
fi

# 5. Copier les fichiers vers Spark
echo -e "\n${BLUE}[5/6] Copie des fichiers vers Spark...${NC}"

# Copier le script de streaming
if [ -f "app/streaming.py" ]; then
    docker cp app/streaming.py spark-master:/opt/spark-apps/
    echo -e "${GREEN}âœ“ streaming.py copiÃ©${NC}"
else
    echo -e "${RED}âŒ app/streaming.py non trouvÃ©!${NC}"
    exit 1
fi

# Copier les modÃ¨les
echo -e "${BLUE}Copie des modÃ¨les ML...${NC}"
docker cp models spark-master:/opt/spark-apps/
echo -e "${GREEN}âœ“ ModÃ¨les copiÃ©s${NC}"

# 6. Configuration Elasticsearch
echo -e "\n${BLUE}[6/6] Configuration de l'index Elasticsearch...${NC}"
sleep 3

# CrÃ©er l'index sentiment-predictions
curl -X PUT "http://localhost:9200/sentiment-predictions" \
  -H 'Content-Type: application/json' \
  -d '{
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 0
    },
    "mappings": {
      "properties": {
        "id": { "type": "keyword" },
        "text": { 
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword" }
          }
        },
        "sentiment": { "type": "keyword" },
        "source": { "type": "keyword" },
        "timestamp": { "type": "date" },
        "predicted_at": { "type": "date" }
      }
    }
  }' 2>/dev/null && \
  echo -e "\n${GREEN}âœ“ Index 'sentiment-predictions' crÃ©Ã©${NC}" || \
  echo -e "\n${YELLOW}Index 'sentiment-predictions' existe dÃ©jÃ ${NC}"

# VÃ©rifier les index
echo -e "\n${GREEN}Index Elasticsearch disponibles:${NC}"
curl -s "http://localhost:9200/_cat/indices?v" | grep -E "sentiment|health"

# 7. DÃ©marrer Spark Streaming
echo -e "\n${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${BLUE}DÃ‰MARRAGE DU SPARK STREAMING${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "\n${YELLOW}Le streaming va traiter les commentaires du topic 'tweets-validated'${NC}"
echo -e "${YELLOW}Assurez-vous que NiFi envoie des donnÃ©es vers Kafka${NC}\n"

read -p "Voulez-vous dÃ©marrer le streaming maintenant? (y/n): " -n 1 -r
echo

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo -e "\n${BLUE}Lancement du Spark Streaming...${NC}"
    
    # Option 1: Lancer en mode interactif (voir les logs)
    docker exec -it spark-master spark-submit \
      --master local[*] \
      --driver-memory 4g \
      --executor-memory 4g \
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
      /opt/spark-apps/streaming.py
    
    # Option 2: Lancer en arriÃ¨re-plan (dÃ©commenter si nÃ©cessaire)
    # docker exec -d spark-master spark-submit \
    #   --master local[*] \
    #   --driver-memory 4g \
    #   --executor-memory 4g \
    #   --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
    #   /opt/spark-apps/streaming.py
    # 
    # echo -e "${GREEN}âœ“ Spark Streaming dÃ©marrÃ© en arriÃ¨re-plan${NC}"
    # echo -e "Pour voir les logs: ${YELLOW}docker logs -f spark-master${NC}"
else
    echo -e "${YELLOW}Streaming non dÃ©marrÃ©${NC}"
fi

# 8. Instructions finales
echo -e "\n${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${GREEN}CONFIGURATION TERMINÃ‰E${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"

echo -e "\n${BLUE}ğŸ“Š Services disponibles:${NC}"
echo -e "  â€¢ Spark UI:          ${YELLOW}http://localhost:8080${NC}"
echo -e "  â€¢ Spark Jobs:        ${YELLOW}http://localhost:4040${NC}"
echo -e "  â€¢ Elasticsearch:     ${YELLOW}http://localhost:9200${NC}"
echo -e "  â€¢ Kibana:            ${YELLOW}http://localhost:5601${NC}"

echo -e "\n${BLUE}ğŸ“‹ Topics Kafka:${NC}"
echo -e "  â€¢ Input:  ${YELLOW}tweets-validated${NC} (depuis NiFi + API YouTube)"
echo -e "  â€¢ Output: ${YELLOW}sentiment-results${NC} (prÃ©dictions ML)"

echo -e "\n${BLUE}ğŸ“ˆ Index Elasticsearch:${NC}"
echo -e "  â€¢ ${YELLOW}sentiment-predictions${NC} (stockage des prÃ©dictions)"

echo -e "\n${BLUE}ğŸ”§ Commandes utiles:${NC}"
echo -e "  â€¢ DÃ©marrer streaming:  ${YELLOW}docker exec -it spark-master spark-submit --master local[*] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 /opt/spark-apps/streaming.py${NC}"
echo -e "  â€¢ Voir logs Spark:     ${YELLOW}docker logs -f spark-master${NC}"
echo -e "  â€¢ Compter messages:    ${YELLOW}curl http://localhost:9200/sentiment-predictions/_count?pretty${NC}"
echo -e "  â€¢ Lire topic Kafka:    ${YELLOW}docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic sentiment-results --from-beginning${NC}"

echo -e "\n${BLUE}ğŸ“Š Configuration Kibana:${NC}"
echo -e "  1. Ouvrir ${YELLOW}http://localhost:5601${NC}"
echo -e "  2. Aller dans Management â†’ Index Patterns"
echo -e "  3. CrÃ©er pattern: ${YELLOW}sentiment-predictions${NC}"
echo -e "  4. Champ de temps: ${YELLOW}predicted_at${NC}"
echo -e "  5. CrÃ©er des visualisations dans Dashboard"

echo -e "\n${GREEN}âœ“ PrÃªt Ã  traiter les commentaires YouTube en temps rÃ©el!${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n"